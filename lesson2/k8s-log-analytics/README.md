# Production Kubernetes Log Analytics Platform

A production-grade demonstration of container image optimization techniques in a real-world Kubernetes microservices architecture.

## üéØ Learning Objectives

This project demonstrates enterprise-level container image optimization through:

- **Multi-stage Docker builds** reducing image sizes by 85%+
- **Layer caching strategies** cutting CI/CD build times from minutes to seconds
- **Security hardening** using minimal base images (Alpine, distroless, scratch)
- **Production Kubernetes patterns** including HPA, PDB, network policies
- **Complete observability** with Prometheus, Grafana, and custom metrics

## üìä Image Optimization Results

| Service | Before | After | Reduction | Strategy |
|---------|--------|-------|-----------|----------|
| Python API | 1.1GB | 165MB | 85% | Multi-stage + slim base |
| Node.js Frontend | 890MB | 95MB | 89% | Static build + nginx |
| Go Processor | 370MB | 8MB | 98% | Static binary + scratch |

## üèóÔ∏è Architecture

The system consists of three optimized microservices:

1. **API Service** (Python/FastAPI) - Log ingestion and query API
2. **Frontend** (React) - Real-time analytics dashboard
3. **Log Processor** (Go) - Asynchronous log processing

Supporting infrastructure:
- Redis for caching and message passing
- Prometheus for metrics collection
- Grafana for visualization
- Kubernetes for orchestration

## üöÄ Quick Start

### Prerequisites

- Docker 20.10+
- Kubernetes 1.28+ (kind, minikube, or cloud provider)
- kubectl
- Helm 3.12+
- kind (for local development)

### Build All Images

```bash
./scripts/build.sh
```

This builds all three optimized microservices and shows final image sizes.

### Setup Local Cluster

```bash
./scripts/setup-cluster.sh
```

Creates a 3-node kind cluster and loads images.

### Deploy Application

```bash
./scripts/deploy.sh
```

Deploys all services to the `log-analytics` namespace.

### Access Services

```bash
# Frontend Dashboard
kubectl port-forward -n log-analytics svc/frontend 3000:3000

# API Service
kubectl port-forward -n log-analytics svc/api-service 8000:8000

# Open browser
open http://localhost:3000
```

## üß™ Testing

### Run Load Test

```bash
# Port-forward API service first
kubectl port-forward -n log-analytics svc/api-service 8000:8000 &

# Generate 1000 log entries
./scripts/load-test.sh http://localhost:8000 1000
```

### View Metrics

```bash
# API Service metrics
curl http://localhost:8000/metrics

# Query logs
curl -X POST http://localhost:8000/logs/query \
  -H "Content-Type: application/json" \
  -d '{"service": "load-test", "limit": 10}'
```

### Observe Autoscaling

```bash
# Watch HPA in action
kubectl get hpa -n log-analytics -w

# Generate load
./scripts/load-test.sh http://localhost:8000 5000
```

## üìä Monitoring

### Setup Prometheus & Grafana

```bash
./scripts/monitoring-setup.sh
```

### Access Grafana

```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3001:80

# Get password
kubectl get secret -n monitoring prometheus-grafana \
  -o jsonpath='{.data.admin-password}' | base64 -d
```

Open http://localhost:3001 (username: admin)

## üîß Image Optimization Deep Dive

### Python API Service

**Key Optimizations:**
```dockerfile
# Before: python:3.11 (1.1GB)
# After: python:3.11-slim (165MB)

# 1. Multi-stage build separates build and runtime
FROM python:3.11-slim AS builder
RUN pip install --user -r requirements.txt

FROM python:3.11-slim
COPY --from=builder /root/.local /root/.local
```

**Impact:**
- 85% size reduction
- Faster pod startup: 8s ‚Üí 2s
- Reduced attack surface: 200 CVEs ‚Üí 15 CVEs

### Node.js Frontend

**Key Optimizations:**
```dockerfile
# Build stage
FROM node:18-alpine AS builder
RUN npm ci && npm run build

# Runtime stage
FROM nginx:1.25-alpine
COPY --from=builder /build/build /usr/share/nginx/html
```

**Impact:**
- Static files only in production image
- nginx is 5MB vs Node.js 180MB
- Zero Node.js vulnerabilities in production

### Go Log Processor

**Key Optimizations:**
```dockerfile
FROM golang:1.21-alpine AS builder
RUN CGO_ENABLED=0 go build -ldflags='-w -s' -o app

FROM scratch
COPY --from=builder /build/app /app
```

**Impact:**
- 98% size reduction (370MB ‚Üí 8MB)
- Static binary with zero dependencies
- Impossible to exec into (security benefit)

## üéì Production Patterns Demonstrated

### Horizontal Pod Autoscaling (HPA)

```yaml
spec:
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

Scales pods based on CPU/memory utilization.

### Pod Disruption Budgets (PDB)

```yaml
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: api-service
```

Ensures high availability during voluntary disruptions.

### Network Policies

```yaml
spec:
  podSelector:
    matchLabels:
      app: api-service
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
```

Zero-trust networking - explicit allow rules.

### Health Checks

Every service implements:
- **Liveness probe**: Is the container alive?
- **Readiness probe**: Can it serve traffic?

## üîç Troubleshooting

### Images Not Pulling

```bash
# Verify images loaded in kind
docker exec -it log-analytics-control-plane crictl images
```

### Pods Stuck in Pending

```bash
# Check events
kubectl describe pod <pod-name> -n log-analytics

# Check resource quotas
kubectl describe nodes
```

### Connection Issues

```bash
# Test service connectivity
kubectl run -it --rm debug --image=alpine --restart=Never -- sh
apk add curl
curl http://api-service.log-analytics:8000/health
```

## üìà Performance Metrics

### Build Time Improvements

| Service | Without Cache | With Cache | Speedup |
|---------|--------------|------------|---------|
| Python API | 180s | 8s | 22.5x |
| Node.js Frontend | 240s | 12s | 20x |
| Go Processor | 45s | 3s | 15x |

### Deployment Velocity

- Pod startup time: 8s ‚Üí 2s (75% improvement)
- Scale-out time: 47s ‚Üí 8s (83% improvement)
- Rolling update time: 120s ‚Üí 30s (75% improvement)

### Cost Savings (Estimated)

- Registry storage: $600/mo ‚Üí $100/mo (83% reduction)
- Network egress: $800/mo ‚Üí $200/mo (75% reduction)
- Compute overhead: -15% (smaller images = better bin-packing)

## üßπ Cleanup

```bash
./scripts/cleanup.sh
```

Deletes all resources and removes the kind cluster.

## üìö Additional Resources

- [Docker Multi-Stage Builds](https://docs.docker.com/build/building/multi-stage/)
- [Kubernetes Best Practices](https://kubernetes.io/docs/concepts/configuration/overview/)
- [Container Image Security](https://kubernetes.io/docs/concepts/security/pod-security-standards/)

## üéØ Next Steps

After completing this lesson, you'll understand:

1. ‚úÖ How to build production-optimized container images
2. ‚úÖ Layer caching strategies for faster CI/CD
3. ‚úÖ Security implications of base image selection
4. ‚úÖ Kubernetes deployment patterns for high availability
5. ‚úÖ How image size impacts cluster performance and cost

**Next Lesson**: Container Networking & Storage - Learn how these optimized services communicate and persist data in Kubernetes.

## üìù License

MIT License - Free for educational use
